{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f771486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe81583",
   "metadata": {},
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0963fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\vickj\\OneDrive\\Documents\\Foundations of data engineering (Mtech)\\03_Udemy_DeepLearning\\ANN\\Dataset\\Part 1 - Artificial Neural Networks\\Churn_Modelling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67a6b53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab2409f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CustomerId\n",
      "Gender            \n",
      "Female        4543\n",
      "Male          5457\n"
     ]
    }
   ],
   "source": [
    "Gender_table1 = dataset.pivot_table(index='Gender', values='CustomerId', aggfunc='count')\n",
    "print(Gender_table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd7b358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           CustomerId\n",
      "Geography            \n",
      "France           5014\n",
      "Germany          2509\n",
      "Spain            2477\n"
     ]
    }
   ],
   "source": [
    "Geography_table1 = dataset.pivot_table(index='Geography', values='CustomerId', aggfunc='count')\n",
    "print(Geography_table1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea73933",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34de4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "# .values will convert dataset values to numpy Array\n",
    "# iloc means integer location based indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "280a6879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' ... 1 1 101348.88]\n",
      " [608 'Spain' 'Female' ... 0 1 112542.58]\n",
      " [502 'France' 'Female' ... 1 0 113931.57]\n",
      " ...\n",
      " [709 'France' 'Female' ... 0 1 42085.58]\n",
      " [772 'Germany' 'Male' ... 1 0 92888.52]\n",
      " [792 'France' 'Female' ... 1 0 38190.78]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12af04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the gender coloumn binary its also called \"Label Encoding\"\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb315155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding the \"Geography\" column\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fef09a",
   "metadata": {},
   "source": [
    "# Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3354fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac200c4e",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adec8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "def scale_features(X_train, X_test):\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "    X_train_scaled = (X_train - mean) / std\n",
    "    X_test_scaled = (X_test - mean) / std\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c236e0",
   "metadata": {},
   "source": [
    "# Creating ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0148e342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vickj\\AppData\\Local\\Temp\\ipykernel_21648\\2912591432.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x.astype(float)))  # Explicitly cast to float\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7795829282479796\n",
      "Epoch 1000, Loss: 0.2058749994558309\n",
      "Epoch 2000, Loss: 0.20587499945575985\n",
      "Epoch 3000, Loss: 0.20587499945568874\n",
      "Epoch 4000, Loss: 0.20587499945561763\n",
      "Epoch 5000, Loss: 0.20587499945554652\n",
      "Epoch 6000, Loss: 0.20587499945547538\n",
      "Epoch 7000, Loss: 0.2058749994554042\n",
      "Epoch 8000, Loss: 0.20587499945533302\n",
      "Epoch 9000, Loss: 0.20587499945526178\n",
      "Accuracy: 0.805\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases\n",
    "        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
    "        self.bias_hidden = np.zeros((1, hidden_size))\n",
    "        self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
    "        self.bias_output = np.zeros((1, output_size))\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x.astype(float)))  # Explicitly cast to float\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward propagation\n",
    "        self.hidden_output = self.sigmoid(np.dot(X, self.weights_input_hidden) + self.bias_hidden)\n",
    "        self.final_output = self.sigmoid(np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output)\n",
    "        return self.final_output\n",
    "\n",
    "    def backward(self, X, y, learning_rate):\n",
    "        # Backward propagation\n",
    "        error = y - self.final_output\n",
    "        output_delta = error * self.sigmoid_derivative(self.final_output)\n",
    "\n",
    "        hidden_layer_error = output_delta.dot(self.weights_hidden_output.T)\n",
    "        hidden_layer_delta = hidden_layer_error * self.sigmoid_derivative(self.hidden_output)\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.weights_hidden_output += self.hidden_output.T.dot(output_delta) * learning_rate\n",
    "        self.bias_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
    "        self.weights_input_hidden += X.T.dot(hidden_layer_delta) * learning_rate\n",
    "        self.bias_hidden += np.sum(hidden_layer_delta, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            # Forward and backward for each epoch\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, learning_rate)\n",
    "\n",
    "            # Print loss for every 1000 epochs\n",
    "            if epoch % 1000 == 0:\n",
    "                loss = np.mean(np.square(y - output))\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Make predictions\n",
    "        return self.forward(X)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have your dataset X and corresponding labels y\n",
    "# (X_train, y_train, X_test, y_test for training and testing)\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 10\n",
    "output_size = 1\n",
    "\n",
    "# Create a neural network\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "# Train the neural network\n",
    "nn.train(X_train, y_train.reshape(-1, 1), epochs=10000, learning_rate=0.01)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = nn.predict(X_test)\n",
    "\n",
    "# Threshold predictions (assuming binary classification)\n",
    "threshold = 0.5\n",
    "binary_predictions = (predictions > threshold).astype(int)\n",
    "\n",
    "# Evaluate accuracy or other metrics\n",
    "accuracy = np.mean(binary_predictions == y_test.reshape(-1, 1))\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09835ee",
   "metadata": {},
   "source": [
    "## Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c9afc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vickj\\AppData\\Local\\Temp\\ipykernel_21648\\2912591432.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x.astype(float)))  # Explicitly cast to float\n"
     ]
    }
   ],
   "source": [
    "print(nn.predict(np.array([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc5921",
   "metadata": {},
   "source": [
    "# Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e6fdfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions vs Actual Labels:\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vickj\\AppData\\Local\\Temp\\ipykernel_21648\\2912591432.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x.astype(float)))  # Explicitly cast to float\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have your dataset X_test and corresponding labels y_test\n",
    "# (X_test, y_test for testing)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = nn.predict(X_test)\n",
    "\n",
    "# Threshold predictions (assuming binary classification)\n",
    "threshold = 0.5\n",
    "y_pred = (predictions > threshold).astype(int)\n",
    "\n",
    "# Print the predictions and actual labels side by side\n",
    "result = np.concatenate((binary_predictions.reshape(len(binary_predictions), 1), y_test.reshape(len(y_test), 1)), 1)\n",
    "print(\"Predictions vs Actual Labels:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74185819",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef315d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1610    0]\n",
      " [ 390    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.805"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6fff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
